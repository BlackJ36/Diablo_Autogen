{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4320b5-48cc-4c6f-91f7-1d79a751205f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing in the following ways:\\n\\n1. Automated testing: Langsmith can be used to automate testing processes, making it quicker and more efficient to run tests on code.\\n\\n2. Test case generation: Langsmith can help generate test cases based on the code being tested, ensuring that all possible scenarios are covered.\\n\\n3. Code coverage analysis: Langsmith can provide insights into how much of the code is being tested, helping developers identify areas that need more testing.\\n\\n4. Performance testing: Langsmith can be used to test the performance of code, identifying any bottlenecks or areas for optimization.\\n\\n5. Regression testing: Langsmith can help run regression tests to ensure that new code changes do not break existing functionality.\\n\\nOverall, Langsmith can streamline the testing process and help developers ensure the quality and reliability of their code.')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_base=\"https://oneapi.xty.app/v1\",openai_api_key=\"sk-OqlsJwGTMdD1ujTG02Bb0fE08b7f4b30B07d8e83012bA8A8\")\n",
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6752f4df-a6dd-4d0f-b696-c02f85ac7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de548789-af07-4a40-aa4e-e0a80718898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6f13f3-a0e4-4a83-8725-f689589a4f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith can help with testing in several ways:\\n\\n1. Automated Testing: Langsmith can generate test cases automatically based on the grammar rules defined for a language. This can help in quickly generating a large number of test cases to cover various scenarios.\\n\\n2. Test Data Generation: Langsmith can generate test data for different types of inputs required for testing, such as strings, numbers, dates, etc. This can help in creating diverse test scenarios for thorough testing.\\n\\n3. Test Scenario Generation: Langsmith can generate test scenarios based on the defined grammar rules, helping in creating comprehensive test cases that cover various paths and conditions.\\n\\n4. Test Case Documentation: Langsmith can automatically document the generated test cases, making it easier for testers to understand the test scenarios and expected outcomes.\\n\\n5. Integration with Testing Frameworks: Langsmith can integrate with popular testing frameworks like JUnit, NUnit, etc., to seamlessly incorporate the generated test cases into existing testing processes.\\n\\nBy leveraging Langsmith's capabilities in automated test case generation, test data generation, and test scenario generation, testers can improve the efficiency and effectiveness of their testing efforts.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\":\"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48fe1811-db41-425d-b6f4-0ab1eee4078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e63205-4985-478c-9ad2-aed69251e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a0677f-f443-465d-8e37-99a58b169831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langsmith can help with testing in several ways:\\n\\n1. Automated Testing: Langsmith can generate test cases automatically based on the grammar rules defined for a language. This can help in quickly generating a large number of test cases to cover various scenarios.\\n\\n2. Test Data Generation: Langsmith can generate test data for different types of inputs required for testing, such as strings, numbers, dates, etc. This can help in creating diverse test scenarios for thorough testing.\\n\\n3. Test Scenario Generation: Langsmith can generate test scenarios based on the defined grammar rules, helping in creating comprehensive test cases that cover various paths and conditions.\\n\\n4. Test Case Documentation: Langsmith can automatically document the generated test cases, making it easier for testers to understand the test scenarios and expected outcomes.\\n\\n5. Integration with Testing Frameworks: Langsmith can integrate with popular testing frameworks like JUnit, NUnit, etc., to seamlessly incorporate the generated test cases into existing testing processes.\\n\\nBy leveraging Langsmith's capabilities in automated test case generation, test data generation, and test scenario generation, testers can improve the efficiency and effectiveness of their testing efforts.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\":\"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4220dcee-8e99-4aae-9aa5-34a23d6f1317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in e:\\anaconda\\envs\\pyautogen\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\anaconda\\envs\\pyautogen\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03cc4d9c-d2a6-4f42-b4e6-6e6ddbec9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c0c88b-c96b-4fde-b477-eb4e49f81844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_base=\"https://oneapi.xty.app/v1\",openai_api_key=\"sk-OqlsJwGTMdD1ujTG02Bb0fE08b7f4b30B07d8e83012bA8A8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2e3dd34-b078-4576-abcc-99e984c58adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in e:\\anaconda\\envs\\pyautogen\\lib\\site-packages (1.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c46ce99-2c73-46fd-a1ba-d55757647377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "048cb873-0380-4527-b6b2-20d507ce1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2abf344d-a106-438f-9cb9-e04c9b45f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46bf99b5-aecc-42cd-bb03-9f62ae4fa4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with testing by providing capabilities to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. It also seamlessly integrates with LangChain, an open source framework for building with LLMs. Additionally, LangSmith offers tracing and evaluation quick starts to assist with testing processes.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3bd992c-b387-41ee-a039-7d6f3fcfd2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2874d1ac-0be6-4de4-a3c2-9b2d0d5dcb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51e50406-cdfb-449d-ac7b-25b602abb33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help with testing by allowing you to visualize test results.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e3770-dd9d-4b33-9d67-776360cc18f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce288224-807c-4390-9b36-a4fd58a32255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d14236bd-ff20-4b06-a675-893be3b0ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with testing by providing capabilities to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. It also seamlessly integrates with LangChain, an open source framework for building with LLMs. Additionally, LangSmith offers tracing and evaluation quick starts to assist with testing processes.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "782e832a-5b17-4415-8e68-ecaef1592b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bc8a514-8ee7-449a-b72f-c24919727d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain-community tavily-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b690a513-7984-49e1-82db-e1ec4ceffcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51f8bcea-5202-453e-b976-98593cfadb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "847f9028-4433-4591-a6f3-4add25d7b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d80bfd27-a39b-4f20-ab0d-6f65dc4dd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "097fa92e-5866-4ded-8e5b-4be2aa87c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23818be1-f7a9-44b0-a709-69d1e96fa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install langchainhub -c conda-forge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "005d3abc-91b4-47ec-9d39-f8f91b851559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0,openai_api_base=\"https://oneapi.xty.app/v1\",openai_api_key=\"sk-OqlsJwGTMdD1ujTG02Bb0fE08b7f4b30B07d8e83012bA8A8\")\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9645931-bd7b-476e-92e1-9c096a2c1ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM (Large Language Model) applications. It can help with testing by allowing you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. \n",
      "\n",
      "You can use LangSmith for tracing, evaluation, and monitoring your LLM applications. It supports various workflows at each stage of the LLM application lifecycle. Additionally, LangSmith offers capabilities for tracing, evaluation, and a Prompt Hub for managing prompts.\n",
      "\n",
      "If you are interested in using LangSmith for testing, you can explore its user guide, setup instructions, pricing model, self-hosting options, and other resources available on the LangSmith platform.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM (Large Language Model) applications. It can help with testing by allowing you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. \\n\\nYou can use LangSmith for tracing, evaluation, and monitoring your LLM applications. It supports various workflows at each stage of the LLM application lifecycle. Additionally, LangSmith offers capabilities for tracing, evaluation, and a Prompt Hub for managing prompts.\\n\\nIf you are interested in using LangSmith for testing, you can explore its user guide, setup instructions, pricing model, self-hosting options, and other resources available on the LangSmith platform.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0c3c268-5d4e-4609-874c-809f48b03ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"Weather in San Francisco is {'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1708498260, 'localtime': '2024-02-20 22:51'}, 'current': {'last_updated_epoch': 1708497900, 'last_updated': '2024-02-20 22:45', 'temp_c': 11.1, 'temp_f': 52.0, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 2.2, 'wind_kph': 3.6, 'wind_degree': 10, 'wind_dir': 'N', 'pressure_mb': 1019.0, 'pressure_in': 30.09, 'precip_mm': 0.15, 'precip_in': 0.01, 'humidity': 93, 'cloud': 75, 'feelslike_c': 11.5, 'feelslike_f': 52.6, 'vis_km': 14.0, 'vis_miles': 8.0, 'uv': 1.0, 'gust_mph': 2.2, 'gust_kph': 3.6}}\"}, {'url': 'https://www.peoplesweather.com/weather/San+Francisco/?date=2024-02-21', 'content': 'Get your weather updates for San Francisco as seen on our Detailed Bulletin on People°s Weather DStv Channel 180 and Openview Channel 115. ... Wednesday 21 February 2024. 13°C 10°C: 10% . Cloud Cover: 100%. SE / 8km/h. Light Breeze. Chance of Rain: Morning: 10°C: Overcast. Cool: Afternoon: 13°C: Partly Cloudy. Cool: Night: 11°C: Clear. Cool'}, {'url': 'https://www.mercurynews.com/2024/02/20/more-isolated-storm-showers-likely-for-bay-area-following-day-of-heavy-rain/', 'content': \"Today's e-Edition\\nGet Morning Report and other email newsletters\\nWeather |\\nMore isolated storm showers likely for Bay Area…\\nShare this:\\nGet Morning Report and other email newsletters\\nToday's e-Edition\\nTrending:\\nBreaking News\\nWeather |\\nCrazy Monday weather: Sun, rain, wind, repeat on Tuesday\\nNews\\nWeather\\nWeather |\\nMore isolated storm showers likely for Bay Area following day of heavy rain\\nForecasters said some thunder and lightning possible for region\\nHeavy rain blew sideways at times during a storm Monday that left much of the Bay Area soaked, much like water being tossed from a bucket. My in-laws expect me to follow their household routine\\nVote now: Bay Area News Group girls athlete of the week\\nVote now: Bay Area News Group boys athlete of the week\\nHarriette Cole: I’m feeling uneasy about how my child is growing up\\nTrending Nationally\\nMore in Weather\\nWeather |\\nCrazy Monday weather: Sun, rain, wind, repeat on Tuesday\\nWeather |\\nWarnings issued as Bay Area storm blows in; My wife finally told me what’s troubling her, and it shook me\\nBay Area tech layoffs finally start to weigh down region’s job market\\nDear Abby: My boyfriend’s mom is trying to restrict my visits to him at college\\nAsk Amy: I think it’s time to confront my teen about his new living situation\\nPrince William will block Harry’s royal return; he and Meghan ‘cannot be trusted’: report\\nHarriette Cole: Those likely to face the most powerful of the isolated showers are in the North Bay, he said, the same area that got the brunt of the previous two storms. Miller said a lighter rain system than the previous ones is making its way to the region and that it could result in rain for areas of the region by late Friday or early Saturday.\\n\"}, {'url': 'https://world-weather.info/forecast/usa/san_francisco/february-2024/', 'content': 'Extended weather forecast in San Francisco. Hourly Week 10 days 14 days 30 days Year. Detailed ⚡ San Francisco Weather Forecast for February 2024 - day/night 🌡️ temperatures, precipitations - World-Weather.info.'}, {'url': 'https://www.wunderground.com/history/daily/us/ca/san-francisco/KCASANFR2031/date/2024-2-21', 'content': 'Current Weather for Popular Cities . San Francisco, CA warning 53 ° F Cloudy; Manhattan, NY 33 ° F Clear; Schiller Park, IL (60176) 50 ° F Clear; Boston, MA 30 ° F Clear; Houston, TX 68 ° F Clear'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in San Francisco is partly cloudy with a temperature of 52.0°F (11.1°C). The wind is blowing at 3.6 km/h from the north, and there is a 75% cloud cover. The humidity is at 93%, and the visibility is 8.0 miles.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the weather in SF?',\n",
       " 'output': 'The current weather in San Francisco is partly cloudy with a temperature of 52.0°F (11.1°C). The wind is blowing at 3.6 km/h from the north, and there is a 75% cloud cover. The humidity is at 93%, and the visibility is 8.0 miles.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is the weather in SF?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be0aaf99-0455-44a7-9814-2428d19234b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'LangSmith LLM application testing services'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM applications. It allows you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. \n",
      "\n",
      "You can use LangSmith to test your LLM applications by following the workflows supported at each stage of the LLM application lifecycle. Additionally, you can utilize the tracing and evaluation capabilities of LangSmith to ensure the quality and performance of your applications.\n",
      "\n",
      "If you need more detailed information or assistance with using LangSmith for testing your LLM applications, you can refer to the LangSmith User Guide, setup instructions, pricing details, and other resources available on the LangSmith platform.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM applications. It allows you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. \\n\\nYou can use LangSmith to test your LLM applications by following the workflows supported at each stage of the LLM application lifecycle. Additionally, you can utilize the tracing and evaluation capabilities of LangSmith to ensure the quality and performance of your applications.\\n\\nIf you need more detailed information or assistance with using LangSmith for testing your LLM applications, you can refer to the LangSmith User Guide, setup instructions, pricing details, and other resources available on the LangSmith platform.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "agent_executor.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a376c-e1d0-4c3e-8bc5-beee36a05f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyautogen",
   "language": "python",
   "name": "pyautogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
